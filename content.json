{"pages":[{"title":"About Me","text":"无名之辈","link":"/about/index.html"},{"title":"","text":"WIDGET = {FID: 'lYJ94FouCD'} 谷歌 必应 百度 常用网址 收藏夹","link":"/navi/index.html"},{"title":"","text":"{\"categories\":[{\"name\":\"公司\",\"sites\":[{\"title\":\"OA\",\"url\":\"https://oa.huya.com/index.html#/mains\"},{\"title\":\"日志后台\",\"url\":\"https://ffilelogweb.huya.com/indexpage.html\"},{\"title\":\"YY UID查询\",\"url\":\"http://webdb.yyembed.yy.com/webdb\"},{\"title\":\"jenkins构建\",\"url\":\"https://jenkins.huya.com/\"},{\"title\":\"看板-主播基础平台组-TAPD平台\",\"url\":\"https://www.tapd.cn/39551029/board/index?board_id=1139551029001000094&board_type=standard&view_type=standard-board\"},{\"title\":\"sre业务支持系统\",\"url\":\"https://sre.huya.com/\"},{\"title\":\"游戏直播管理后台\",\"url\":\"http://admin.huya.com/login/\"}]},{\"name\":\"C++\",\"sites\":[{\"title\":\"cppreference\",\"url\":\"https://en.cppreference.com/w/\"},{\"title\":\"C++ Core Guidelines\",\"url\":\"https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md\"},{\"title\":\"coliru在线编译\",\"url\":\"http://coliru.stacked-crooked.com/\"},{\"title\":\"7 Features of C++17 that will simplify your code\",\"url\":\"https://www.codingame.com/playgrounds/2205/7-features-of-c17-that-will-simplify-your-code/introduction\"}]},{\"name\":\"Unity\",\"sites\":[{\"title\":\"2018.4文档\",\"url\":\"https://docs.unity3d.com/2018.4/Documentation/Manual/\"},{\"title\":\"UGUI基础！界面拼接！\",\"url\":\"https://zhuanlan.zhihu.com/p/28905447\"},{\"title\":\"Unity - Manual: Execution Order of Event Functions\",\"url\":\"https://docs.unity3d.com/2018.2/Documentation/Manual/ExecutionOrder.html\"},{\"title\":\"Unity - Manual: Getting started with Android development\",\"url\":\"https://docs.unity3d.com/Manual/android-GettingStarted.html\"},{\"title\":\"Unity教程 用户界面（UI）_w3cschool\",\"url\":\"https://www.w3cschool.cn/unity3d_jc/unity3d_jc-8lea2dkb.html\"},{\"title\":\"Unity 2018.4 中文手册 中文文档\",\"url\":\"https://unity2018.docs.zlogn.com/\"},{\"title\":\"Unity Play Video On Canvas | Learn Unity Mir Imad Ahmed\",\"url\":\"https://www.mirimad.com/unity-play-video-on-canvas/\"},{\"title\":\"Video - Change/Detect video orientation\",\"url\":\"https://forum.unity.com/threads/change-detect-video-orientation.546450/\"},{\"title\":\"360 VIDEO PLAYER (with VR mode) - Unity Tutorial - YouTube\",\"url\":\"https://www.youtube.com/watch?v=RxlQnPcOoYc\"}]},{\"name\":\"Android\",\"sites\":[{\"url\":\"https://my.oschina.net/lifj/blog/709188\",\"title\":\"［直播一揽子］x264 for Android 的编译\"},{\"url\":\"https://blog.csdn.net/chinabinlang/article/details/46898961\",\"title\":\"X264的ARMV7-a的交叉编译及优化运行\"},{\"url\":\"https://blog.csdn.net/xyang81/article/details/42319789\",\"title\":\"Android NDK开发Crash错误定位\"},{\"url\":\"https://www.jianshu.com/p/73fed068a795\",\"title\":\"Android Camera2 使用总结\"},{\"url\":\"https://www.jianshu.com/p/d83161e77e90\",\"title\":\"Android进阶——你所知道的Camera2和你所不知道的Camera2完全解析\"},{\"url\":\"https://source.android.com/devices/graphics/arch-egl-opengl\",\"title\":\"EGLSurface 和 OpenGL ES | Android Open Source Project\"},{\"url\":\"https://www.jianshu.com/p/c085af435d88\",\"title\":\"「音视频直播技术」Android下视频H264编码\"},{\"url\":\"https://juejin.im/post/5aefdb2c51882522835e6542\",\"title\":\"《OpenGL ES 2.0 for Android》读书笔记\"},{\"url\":\"https://www.khronos.org/registry/EGL/\",\"title\":\"Khronos EGL Registry - The Khronos Group Inc\"},{\"url\":\"https://developer.android.com/training/graphics/opengl/environment#java\",\"title\":\"Build an OpenGL ES environment | Android Developers\"},{\"url\":\"https://source.android.com/devices/graphics/architecture.html\",\"title\":\"图形架构 | Android Open Source Project\"},{\"url\":\"https://blog.csdn.net/cmsbupt/article/details/9815685\",\"title\":\"Android系统中YUV420p (NV21)到ARGB8888的转换\"},{\"url\":\"https://mp.weixin.qq.com/s/0xek4nnc2zoKpslEyILQmw?comefrom=https://blogread.cn/news/\",\"title\":\"总是听到有人说AndroidX，到底什么是AndroidX？\"},{\"url\":\"https://developer.android.com/guide/topics/media/camera\",\"title\":\"Camera API | Android Developers\"},{\"url\":\"https://developer.android.com/ndk/guides/audio/opensl/opensl-prog-notes.html#kotlin\",\"title\":\"OpenSL ES 编程说明 | Android NDK | Android Developers\"},{\"url\":\"https://developer.android.com/ndk/guides/audio/opensl/opensl-for-android\",\"title\":\"面向 Android 的 OpenSL ES | Android NDK | Android Developers\"},{\"url\":\"https://developer.android.com/ndk/guides/stable_apis\",\"title\":\"Android NDK 原生 API | Android Developers\"},{\"url\":\"http://www.soomal.com/doc/10100006276.htm\",\"title\":\"Gabor、Patrick作品 - Android的10毫秒问题 解读Android系统音频通道延迟缺陷[Soomal]\"},{\"url\":\"https://developer.android.com/ndk/guides/audio/audio-latency?hl=zh-cn\",\"title\":\"音频延迟 | Android NDK | Android Developers\"}]},{\"name\":\"TCP/IP\",\"sites\":[{\"url\":\"https://gist.github.com/gabrielfalcao/4216897\",\"title\":\"TCP socket error codes\"},{\"url\":\"https://blog.csdn.net/tianlongtc/article/details/80238497\",\"title\":\"TCP快速重传为什么是三次冗余ack\"},{\"url\":\"https://www.zhihu.com/question/21789252\",\"title\":\"TCP快速重传为什么是三次冗余ack，这个三次是怎么定下来的？\"},{\"url\":\"https://www.cnblogs.com/wetest/p/9190786.html\",\"title\":\"可靠UDP，KCP协议快在哪？\"},{\"url\":\"https://blog.csdn.net/qq_36748278/article/details/80171575\",\"title\":\"KCP原理及源码解析\"},{\"url\":\"https://chromium.googlesource.com/chromium/src/+/master/docs/windows_build_instructions.md\",\"title\":\"Checking out and Building Chromium for Windows\"},{\"url\":\"http://jagt.github.io/clumsy/cn/manual.html\",\"title\":\"clumsy, 在 Windows Vista / Windows 7 下模拟劣化网络环境(网络延迟，掉包，重发)的小工具。\"},{\"url\":\"https://zhuanlan.zhihu.com/p/32553477\",\"title\":\"科普：QUIC协议原理分析\"}]},{\"name\":\"iOS\",\"sites\":[{\"url\":\"https://www.jianshu.com/p/eccdcf43d7d2\",\"title\":\"iOS视频开发（一）：视频采集\"},{\"url\":\"https://blog.csdn.net/lincsdnnet/article/details/78255773\",\"title\":\"iOS - 视频采集详解\"},{\"url\":\"https://www.jianshu.com/p/9809760654ea\",\"title\":\"iOS-镜头采集(AVCaptureDevice)\"},{\"url\":\"https://www.jianshu.com/p/019f59a37e1e\",\"title\":\"iOS-镜头采集(Camera capture&amp;AVCaptureSession)\"},{\"url\":\"https://www.jianshu.com/p/d99366dd19e4\",\"title\":\"iOS 相机捕捉\"},{\"url\":\"https://www.jianshu.com/p/8b28892bae5a\",\"title\":\"30分钟搞定iOS自定义相机\"},{\"url\":\"https://www.jianshu.com/p/8c7ca1dd7f02\",\"title\":\"iOS-AVFoundation自定义相机详解\"},{\"url\":\"https://stackoverflow.com/questions/588866/whats-the-difference-between-the-atomic-and-nonatomic-attributes\",\"title\":\"ios - What's the difference between the atomic and nonatomic attributes? - Stack Overflow\"},{\"url\":\"https://github.com/skyming/iOS-Performance-Optimization\",\"title\":\"skyming/iOS-Performance-Optimization: 关于iOS 性能优化梳理、内存泄露、卡顿、网络、GPU、电量、 App 包体积瘦身、启动速度优化等、Instruments 高级技巧、常见的优化技能- Get — Edit\"},{\"url\":\"https://github.com/qinjx/30min_guides/blob/master/ios.md\",\"title\":\"30min_guides/ios.md at master · qinjx/30min_guides\"},{\"url\":\"https://stackoverflow.com/questions/5887248/ios-app-maximum-memory-budget\",\"title\":\"iphone - ios app maximum memory budget - Stack Overflow\"},{\"url\":\"https://blog.csdn.net/bxjie/article/details/39581565\",\"title\":\"关于airplay协议实现镜像功能研究\"},{\"url\":\"https://depthlove.github.io/2015/09/16/build-X264-library-for-iOS-platform/\",\"title\":\"编译iOS平台上使用的X264库 | Minmin.Sun Blog\"}]},{\"name\":\"OpenGL ES\",\"sites\":[{\"url\":\"http://toughcoder.net/blog/2018/07/31/introduction-to-opengl-es-2-dot-0/\",\"title\":\"年轻人的第一篇OpenGL ES 2.0教程\"},{\"url\":\"https://blog.csdn.net/kesalin/column/info/opengl-es2-ios\",\"title\":\"OpenGL ES 2.0 iOS教程\"}]},{\"name\":\"Kotlin\",\"sites\":[{\"url\":\"https://www.kotlincn.net/docs/tutorials/android-plugin.html\",\"title\":\"Kotlin Android扩展\"}]},{\"name\":\"多媒体\",\"sites\":[{\"url\":\"http://blog.csdn.net/leixiaohua1020\",\"title\":\"雷神博客\"},{\"url\":\"http://blog.csdn.net/u011270282/article/details/42058617\",\"title\":\"h.264保存flv文件\"},{\"url\":\"http://blog.csdn.net/yeyumin89/article/details/7932368\",\"title\":\"将h.264视频流封装成flv格式文件（一.flv格式）\"},{\"url\":\"http://blog.csdn.net/yeyumin89/article/details/7932431\",\"title\":\"将h.264视频流封装成flv格式文件（二.开始动手）\"},{\"url\":\"https://segmentfault.com/a/1190000007361184\",\"title\":\"FLV文件格式解析\"},{\"url\":\"http://blog.csdn.net/leixiaohua1020/article/details/17934487\",\"title\":\"视音频编解码学习工程：FLV封装格式分析器\"},{\"url\":\"http://www.tuicool.com/articles/vu2Mvy\",\"title\":\"FLV视频封装格式详解\"},{\"url\":\"http://blog.csdn.net/zhuweigangzwg/article/details/25815851\",\"title\":\"音视频同步(播放)原理\"},{\"url\":\"http://developer.t-firefly.com/thread-5731-1-1.html\",\"title\":\"音视频同步和视频帧率控制的原理和实现\"},{\"url\":\"http://blog.csdn.net/Byeweiyang/article/details/78134674\",\"title\":\"实时视频传输的关键技术 H.264 全解析\"},{\"url\":\"http://blog.csdn.net/shangmingyang/article/details/50837852\",\"title\":\"带你吃透RTMP\"},{\"url\":\"http://blog.csdn.net/liuxingen/article/details/45420455\",\"title\":\"字节序(byte order)和位序(bit order)\"},{\"url\":\"https://blog.csdn.net/leixiaohua1020/article/details/11694129\",\"title\":\"RTMP规范简单分析\"},{\"url\":\"https://my.oschina.net/u/213072/blog/52053\",\"title\":\"FLV视频封装格式详解\"},{\"url\":\"https://depthlove.github.io/2015/11/13/flv-analysis-in-rtmp-live-play/\",\"title\":\"rtmp直播推流（一）－－flv格式解析与封装 | Minmin.Sun Blog\"},{\"url\":\"https://blog.csdn.net/sphone89/article/details/17492433\",\"title\":\"h264 profile &amp; level\"},{\"url\":\"http://www.lighterra.com/papers/videoencodingh264/\",\"title\":\"Video Encoding Settings for H.264 Excellence\"}]},{\"name\":\"FFmpeg\",\"sites\":[{\"url\":\"https://blog.csdn.net/leixiaohua1020\",\"title\":\"雷神博客\"},{\"url\":\"https://www.ffmpeg.org/ffmpeg-filters.html#format-1\",\"title\":\"FFmpeg Filters Documentation\"},{\"url\":\"https://blog.csdn.net/fireroll/article/details/8607954\",\"title\":\"为ffmpeg添加自定义滤镜\"},{\"url\":\"https://blog.csdn.net/dancing_night/article/details/46348515\",\"title\":\"把自定义的demuxer加入ffmpeg源码\"},{\"url\":\"https://blog.csdn.net/wstarx/article/details/1572393\",\"title\":\"FFMpeg框架代码阅读\"},{\"url\":\"https://blog.csdn.net/m0_37402140/article/details/77963538\",\"title\":\"ffmpeg八大模块及常用函数介绍\"},{\"url\":\"https://blog.csdn.net/leixiaohua1020/article/details/15811977\",\"title\":\"[总结]FFMPEG视音频编解码零基础学习方法\"},{\"url\":\"https://juejin.im/post/5cad73425188251aee3a5624\",\"title\":\"三、ffplay、ffmpeg日常食用的简单姿势\"},{\"url\":\"https://blog.csdn.net/Contex_A17/article/details/82014826\",\"title\":\"ffmpeg倒放音视频\"},{\"url\":\"https://blog.csdn.net/vbLittleBoy/article/details/8587745\",\"title\":\"关于ffmpeg如何提取视频的关键帧的问题\"},{\"url\":\"https://www.jianshu.com/p/0f2d762c4d1d\",\"title\":\"FFMpeg中seek函数解析\"},{\"url\":\"https://blog.csdn.net/leixiaohua1020/article/details/44220151\",\"title\":\"FFmpeg源代码结构图 - 解码\"},{\"url\":\"https://blog.csdn.net/CHNIM/article/details/80852806\",\"title\":\"ffmpeg实现视频倒播（基于opencv方法）\"},{\"url\":\"https://stackoverflow.com/questions/42257354/concat-a-video-with-itself-but-in-reverse-using-ffmpeg\",\"title\":\"Concat a video with itself, but in reverse, using ffmpeg - Stack Overflow\"},{\"url\":\"https://blog.csdn.net/ternence_hsu/article/details/85865718\",\"title\":\"ffmpeg 视频倍速播放 和 慢速播放\"},{\"url\":\"https://zhuanlan.zhihu.com/p/44615185\",\"title\":\"ffplay音视频同步分析——基础概念\"},{\"url\":\"https://juejin.im/post/5cad790f51882518b87e1404\",\"title\":\"十、详解FFplay音视频同步\"},{\"url\":\"https://blog.csdn.net/lrzkd/article/details/78661841\",\"title\":\"ffplay播放器音视频同步原理\"},{\"url\":\"https://my.oschina.net/u/735973/blog/806117\",\"title\":\"ffmpeg音视频同步---视频同步到音频时钟\"},{\"url\":\"https://superuser.com/questions/1189472/make-a-clip-from-a-video-with-ffmpeg\",\"title\":\"Make a clip from a video with FFMPEG\"}]},{\"name\":\"CMake\",\"sites\":[{\"url\":\"https://www.cnblogs.com/zl1991/p/6526613.html\",\"title\":\"CMakeLists.txt写法\"},{\"url\":\"https://elloop.github.io/tools/2016-04-10/learning-cmake-2-commands\",\"title\":\"CMake 常用命令和变量\"},{\"url\":\"https://blog.csdn.net/a794226986/article/details/18616511\",\"title\":\"cmake处理多源文件目录的方法\"},{\"url\":\"https://stackoverflow.com/questions/52183875/create-cmake-c-c-library-to-android-without-android-studio\",\"title\":\"Create (Cmake) C/C++ Library to Android without Android Studio\"},{\"url\":\"https://owent.net/2017/1405.html\",\"title\":\"用cmake交叉编译到iOS和Android\"},{\"url\":\"https://fucknmb.com/2017/06/27/cmake-%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91/\",\"title\":\"cmake交叉编译\"},{\"url\":\"https://zhuanlan.zhihu.com/p/24535328\",\"title\":\"更简单的CMake交叉编译\"}]},{\"name\":\"Lua\",\"sites\":[{\"url\":\"https://www.w3cschool.cn/doc_lua_5_3/dict\",\"title\":\"Lua 5.3 词典 速查词典|Lua 5.3 词典 API中文手册|Lua 5.3 词典参考文档_w3cschool\"},{\"url\":\"https://wowwiki.fandom.com/wiki/WoW_AddOn\",\"title\":\"WoW AddOn | WoWWiki | FANDOM powered by Wikia\"},{\"url\":\"https://wowwiki.fandom.com/wiki/UI_FAQ/AddOn_Author_Resources#Resources\",\"title\":\"UI FAQ/AddOn Author Resources | WoWWiki | FANDOM powered by Wikia\"},{\"url\":\"https://bbs.nga.cn/read.php?tid=14839516\",\"title\":\"[狂暴][PVE]8.2争霸艾泽拉斯狂暴专精指南[08/20更新狂暴战8.2版本木桩讲解视频] NGA玩家社区\"},{\"url\":\"http://wowprogramming.com/\",\"title\":\"Home Page - World of Warcraft Programming: A Guide and Reference for Creating WoW Addons\"},{\"url\":\"https://github.com/LewisJEllis/awesome-lua\",\"title\":\"LewisJEllis/awesome-lua: A curated list of quality Lua packages and resources.\"},{\"url\":\"https://luarocks.org/\",\"title\":\"LuaRocks - The Lua package manager\"},{\"url\":\"https://bbs.nga.cn/read.php?tid=17358638\",\"title\":\"[教程] 提取魔兽世界的编码文件和美工文件+替换技能图标+常用工具 NGA玩家社区\"},{\"url\":\"https://warcraft.huijiwiki.com/wiki/%E6%8F%92%E4%BB%B6%E7%BC%96%E5%86%99%E4%BB%8B%E7%BB%8D\",\"title\":\"插件编写介绍 - 魔兽世界中文维基，自由编辑的魔兽资料库 - 灰机wiki\"},{\"url\":\"http://www.waitingfy.com/archives/1047\",\"title\":\"《魔兽世界插件》教程—21点扑克游戏 Blackjack | Waiting For You\"}]},{\"name\":\"其它\",\"sites\":[{\"url\":\"https://deerchao.cn/tutorials/regex/regex.htm\",\"title\":\"正则30分钟教程\"},{\"url\":\"https://www.cnblogs.com/liuxianan/p/build-blog-website-by-hexo-github.html\",\"title\":\"使用hexo+github搭建免费个人博客详细教程\"},{\"url\":\"https://www.zhihu.com/question/28889256\",\"title\":\"哪一句日常用的英语很简单但是格调和品位很高？\"}]}]}","link":"/navi/favorite.json"},{"title":"","text":"body { background-color:#000; font-family: \"Source Code Pro\", monospace, \"Microsoft YaHei\"; text-align: center; } .default-div { width: 80%; text-align: center; padding: 10px 0; background: #111; background: linear-gradient(#004746, #111); border: 6px solid #00a4a2; box-shadow: 0 0 15px #00fffd; border-radius: 5px; display: inline-block; margin: 100px auto 0; position: relative; } .default-div:hover { border: 6px solid #00fffd; box-shadow: 0 0 25px #00fffd; transition: 1s all ; } input { background: #222; background: linear-gradient(#333, #222); border: 1px solid #444; border-radius: 5px; box-shadow: 0 2px 0 #000; color: #888; display: inline-block; font-family: 'Cabin', helvetica, arial, sans-serif; font-size: 13px; padding: 0 10px; height: 40px; text-shadow: 0 -1px 0 #000; width: 40%; } input:focus { animation: box-glow 1s ease-out infinite alternate; background: #0B4252; background: linear-gradient(#333933, #222922); border-color: #00fffc; box-shadow: 0 0 5px rgba(0, 255, 253, .2), inset 0 0 5px rgba(0, 255, 253, .1), 0 2px 0 #000; color: #efe; outline: none; } input:invalid { border: 2px solid red; box-shadow: 0 0 5px rgba(255, 0, 0, .2), inset 0 0 5px rgba(255, 0, 0, .1), 0 2px 0 #000; } .common-button { background: #222; background: linear-gradient(#333, #222); box-sizing: content-box; border: 1px solid #444; border-left-color: #000; border-radius: 5px; box-shadow: 0 2px 0 #000; color: #fff; display: inline-block; font-family: 'Cabin', helvetica, arial, sans-serif; font-size: 13px; font-weight: 400; margin: 20px auto; padding: 0 18px; height: 40px; position: relative; text-shadow: 0 -1px 0 #000; } .common-button:hover, .common-button:focus { background: #0C6125; background: linear-gradient(#393939, #292929); color: $stark-light-blue; outline: none; } .common-button:active { background: #292929; background: linear-gradient(#393939, #292929); box-shadow: 0 1px 0 #000, inset 1px 0 1px #222; top: 1px; } h2 { color:#eeeeee; } table { padding: 0px 15%; width: 100%; text-align: center; } td { width: 10%; padding: 0px 0px 30px 0px; font-size: 20px; } a:hover { text-decoration:underline; color: #02feff; } a:active, a:hover { outline: 0; } a { background: transparent; text-decoration:none; color: #00a4a2; } hr { align: center; width: 80%; height: 1px; border-width: 0; background-color: #666; noshade: noshade; } .common-select { -webkit-appearance: none; -moz-appearance: none; appearance: none; width: 250px; height: 40px; padding: 0px 10px; font-size: 20px; background-color: #0A2129; color: #fff; border: 1px solid rgb(97, 245, 245); }","link":"/navi/navi.css"},{"title":"","text":"function toGoogle() { let param = document.getElementById(\"searchKey\").value window.open(\"https://www.google.com/search?q=\" + param, \"_blank\") } function toBing() { let param = document.getElementById(\"searchKey\").value window.open(\"https://cn.bing.com/search?q=\" + param, \"_blank\") } function toBaidu() { let param = document.getElementById(\"searchKey\").value window.open(\"https://www.baidu.com/s?wd=\" + param, \"_blank\") } function loadOftenUse() { let request = new XMLHttpRequest(); request.open(\"get\", \"oftenuse.json\"); request.responseType = \"text\"; request.send(); request.onload = function() { let table = document.getElementById(\"oftenTable\"); let data = request.response; let root = JSON.parse(data); let sites = root[\"sites\"]; let row; for (let i = 0; i < sites.length; ++i) { if (i % 6 == 0) { row = table.insertRow(i / 6); } let cell = row.insertCell(i % 6); let site = sites[i]; let a = document.createElement(\"a\"); cell.appendChild(a); a.style.fontSize = 24; a.href = site.url; a.text = site.title; a.target = \"_blank\"; } }; } function loadFavorite() { let request = new XMLHttpRequest(); request.open(\"get\", \"favorite.json\"); request.responseType = \"text\"; request.send(); request.onload = function() { let table = document.getElementById(\"favoriteTable\"); let data = request.response; let root = JSON.parse(data); let categories = root[\"categories\"]; let row; for (let i = 0; i < categories.length; ++i) { let category = categories[i]; if (i % 4 == 0) { row = table.insertRow(i / 4); } let cell = row.insertCell(i % 4); let sel = document.createElement(\"select\"); sel.className = \"common-select\"; cell.appendChild(sel); sel.addEventListener(\"change\", function() { window.open(sel.value, \"_blank\"); sel.selectedIndex = 0; }); let head = document.createElement(\"option\"); sel.appendChild(head); head.text = category.name; head.disabled = true; head.selected = true; let sites = category.sites; for (let i = 0; i < sites.length; ++i) { let site = sites[i]; let op = document.createElement(\"option\"); sel.appendChild(op); op.value = site.url; op.text = site.title; } } }; } function onLoad() { loadOftenUse(); loadFavorite(); }","link":"/navi/navi.js"},{"title":"","text":"{\"sites\":[{\"url\":\"https://aplus.huya.com/#/home/buildProject/index\",\"title\":\"构建系统\"},{\"url\":\"https://ermao.live/\",\"title\":\"我的博客\"},{\"url\":\"https://github.com/\",\"title\":\"github\"},{\"url\":\"https://stackoverflow.com/\",\"title\":\"stackoverflow\"},{\"url\":\"https://en.cppreference.com/w/\",\"title\":\"cppreference\"},{\"url\":\"https://www.ffmpeg.org/documentation.html\",\"title\":\"FFmpeg文档\"},{\"url\":\"https://tech.sina.com.cn/\",\"title\":\"新浪科技\"},{\"url\":\"https://maimai.cn/gossip_list\",\"title\":\"脉脉\"},{\"url\":\"https://www.zhihu.com/\",\"title\":\"知乎\"},{\"url\":\"https://weibo.com/liangzuoting/home?wvr=5\",\"title\":\"微博\"},{\"url\":\"https://v.qq.com/\",\"title\":\"腾讯视频\"},{\"url\":\"https://www.youku.com/\",\"title\":\"优酷\"},{\"url\":\"https://www.iqiyi.com/\",\"title\":\"爱奇艺\"},{\"url\":\"https://www.douyu.com/62081\",\"title\":\"叶落直播间\"},{\"url\":\"https://www.huya.com/11352915\",\"title\":\"老白涮肉坊\"},{\"url\":\"https://www.tmall.com/\",\"title\":\"天猫\"},{\"url\":\"https://www.taobao.com/\",\"title\":\"淘宝\"},{\"url\":\"https://www.ctrip.com/\",\"title\":\"携程\"}]}","link":"/navi/oftenuse.json"}],"posts":[{"title":"Python3 爬虫初体验","text":"数据提取通过 PyCharm 的包管理工具分别下载安装 requests 、bs4 、lxml 库。 requests 库requests 是一个简洁优雅的 HTTP 库，基于 urllib3 再封装。一个 get 请求用一行代码即可实现： 1res = requests.get('https://github.com/') 许多网站会根据 Request Header 识别请求是否来自非爬虫应用，可以通过伪造 Header 骗过，比如，把自己伪装成一个 Chrome 浏览器： 1234headers = { 'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.105 Safari/537.36'}res = requests.get('https://github.com/', headers=headers) 可以通过浏览器的开发者工具获取到完整的头信息列表，做到完美伪装。 BeautifulSoup 和 lxml 库bs4 即 BeautifulSoup ，是一个可以从 HTML 或 XML 文件中提取数据的库。它支持以多种形式遍历、查找 HTML 内容，比如 CSS 的选择器、标签类型甚至正则表达式。BeautifulSoup 可以配合第三方 HTML 解析器使用，比如 lxml 。lxml 运行效率比标准库高，大概算是事实标准库了吧。 基于上述准备工作，即可完成大部分的静态页面内容抓取，比如，获取 GitHub 首页的 body 内容： 123456import requestsfrom bs4 import BeautifulSouprsp = requests.get('https://github.com/')soup = BeautifulSoup(rsp.text, 'lxml')print(soup.find('body')) # 打印出网页 body 内容 配合浏览器的开发者工具，可以拿到网页所有标签的 css selector，据此可以提取出更精细的数据，比如，拿到 GitHub 用户的头像： 12345rsp = requests.get('https://github.com/liangzuoting')soup = BeautifulSoup(rsp.text, 'lxml')img = soup.select('#js-pjax-container &gt; div.container-xl.px-3.px-md-4.px-lg-5 &gt; div &gt; div.flex-shrink-0.col-12.col-md-3.mb-4.mb-md-0 &gt; div &gt; div.clearfix.d-flex.d-md-block.flex-items-center.mb-4.mb-md-0 &gt; div.position-relative.d-inline-block.col-2.col-md-12.mr-3.mr-md-0.flex-shrink-0 &gt; a &gt; img')if len(img) &gt; 0: print(img[0].get('src')) # 打印出头像图片 url BeautifulSoup.select 函数接受一个 css selector 字符串，并返回匹配列表。 数据存储通过 Python 内置的 csv 库，可以很方便的将提取的数据写入到 csv 文件。 1234567import csvf = open('d:\\dd.csv', mode='w', newline='\\n', encoding='utf-8-sig')w = csv.writer(f)w.writerow(['1', '二,三,四', '5\\n6\\n7'])w.writerow(['11', '22,33,44', '55\\n66\\n77'])f.close() 务必显式指定 newline 参数为 \\n，Windows 平台下默认用 \\r\\n 做换行符，在 excel 里打开 csv 文件后出现空白行。 以 utf-8-sig 编码创建文件，能解决非 ascii 码字符乱码问题，sig 即 BOM，显式地把字节序写入到了文件里。 以换行符插入项字符串内，可实现单元格内换行。对以列表存储的动态数据，需要定义自己的字符串格式化函数： 12def ls_to_str(ls): '\\n'.join(map(str, ls)) map 函数把 ls 列表项通过 str 函数依次映射成字符串，这个在列表项是自定义类型时是必须的，否则列表项只记录其地址值。 小结爬虫入门还是很简单的，Python 完整的生态链功不可没。问题总是出在意想不到的地方，比如 Chrome 的弹窗自动拦截。通过开发者工具获取到的 selector 是拦截后页面的层级关系，导致 BeautifulSoup.select 获取的数据总是对不上。可以关闭浏览器的相关功能；或从 requests 导出完整的页面内容，保存成 HTML 文件后再解析。","link":"/2020/08/15/Python%E7%88%AC%E8%99%AB%E5%88%9D%E4%BD%93%E9%AA%8C/"},{"title":"FFmpeg 常用命令合集","text":"视频剪辑 ffmpeg -ss 300 -t 600 -i c:\\input.mp4 c:\\output.mp4 从 input.mp4 的 300s 处开始剪辑，时长 600s，保存到 output.mp4。 note: -ss -t 参数都可应用于输入或输出(ffmpeg -i c:\\input.mp4 -ss 300 -t 600 c:\\output.mp4)上，区别在于：-ss 应用于输入时有性能优势，会先跳转到时间点再进行解码；用于输出时会逐帧解码并丢弃时间点前的所有帧。 下载视频 ffmpeg -i &quot;https://us.sinaimg.cn/0013JKJ9jx07aaEhInRC0104010094440k01.mp4?label=mp4_hd&amp;Expires=1579700718&amp;ssig=wkpUBmK%2B9Y&amp;KID=unistore,video&quot; d:\\output.mp4 从 -i 标识的 url 下载视频保存到 output.mp4。 note: url 包含特殊字符(空格、&amp; 等)时，必须用双引号包含 url 才能正确解析；输出路径同理。 GIF 截图 ffmpeg -y -ss 1:33:28 -t 22 -i input.mp4 -vf &quot;scale=iw*0.3:ih*0.3,drawtext=x=(w-text_w)/2:y=h-40:fontsize=30:fontcolor=white:fontfile=C\\\\:/Windows/Fonts/STXINWEI.TTF:text='这是文字'&quot; -r 15 output.gif 从 input.mp4 的 1:33:28 处开始截取 22 秒；输出尺寸缩小到输入的 0.3 倍；在输出图的中下部分添加文字，文字样式为白色、30像素、新魏；把输出 gif 图的帧率设为 15。 note: 1) 多个 filter 效果以,拼接，且以出现的先后顺序逐个应用到输出上。所以，drawtext 里用到的w、h是缩放后的尺寸；2) 注意fontfile值的表现方式。","link":"/2020/01/21/FFMpeg%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%90%88%E9%9B%86/"},{"title":"2020 年学习规划","text":"2020年会整体围绕StreamingCore项目运作。先期会先做一部分复习工作，比如C++相关、工程相关；其它所列知识点会边学边应用。 尽量详细地列出各项，不断回顾并更新进度。 理论知识复习C++ 《C++ Primer》 ✅ 《Effective Modern C++》 ❌ 《C++标准库》 ✅ 《Effective STL》 ❌ 复习《设计模式》 ✅复习《Kotlin语言官方参考文档》 ✅学习《Swift编程权威指南》 ❌多媒体技术FFmpeg应用能力 ❌ 这里简述成果 OpenGL ES应用能力 ❌ 这里简述成果 Android平台多媒体接口应用 MediaCodec ❌ Camera ❌ Camera2 ❌ iOS平台多媒体接口应用 Audio Unit ❌ AVCapture ❌ ReplayKit ❌ AudioToolBox ❌ VideoToolBox ❌ libx264应用能力 ❌","link":"/2019/12/20/2020%E5%B9%B4%E5%AD%A6%E4%B9%A0%E8%A7%84%E5%88%92/"},{"title":"StreamingCore 项目介绍","text":"是时候驻足整装了明年的业余时间会集中在这个StreamingCore项目上。进入直播行业也有六七年时间了，这将是我迄今的职业生涯中最重要的一份总结。 如同其名，StreamingCore将是一套直播核心流程的解决方案，集成采集、编码、推流功能，同时支持Android和iOS两端。借鉴FFmpeg的设计思想，StreamingCore也会以模块化架构实现，允许独立使用某一功能模块。同一功能模块，或许会提供多套实现方案，以供比较选择。 暂拟定的功能模块音频采集模块 OpenSL ES implementation for Android AudioRecord implementation for Android Audio Unit implementation for iOS 图像采集模块 Implementation based on Camera interface for Android Implementation based on Camera2 interface for Android Implementation based on Virtual Display for Android Implementation based on AVFoundation framework for iOS Implementation based on ReplayKit for iOS 音频编码模块 Audio Encoder implementation based on MediaCodec for Android Audio Encoder implementation based on AudioToolBox for iOS 视频编码模块 Video Encoder implementation based on MediaCodec for Android Video Encoder implementation based on VideoToolBox for iOS 推流模块 Streaming by Rtmp Protocol Streaming by custom Protocol based on UDP 各个模块将暴露标准化接口，供扩展实现。 我不喜欢Java和Objective-C或者反过来说，我喜欢Kotlin和Swift。够简洁，够现代化，这就足够了。公司业务已呈现尾大不掉、积重难返之态，更加之KPI当头，相关负责人没有勇气切换到新的开发环境。我已学的Kotlin，我想学的Swift，几无用武之地，这也是我萌生实施此项目的一个重要原因。 同样基于这个技术决定，项目质量无从保证。成品后能否被接入方接受，就更难说了…… 大概的开发计划 时间周期为一年（2020.1.1——2020.12.31） 先Android端全功能，再iOS端","link":"/2019/12/19/StreamingCore%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D/"},{"title":"在 Unity 项目中使用 OpenFileDialog 实现选择文件功能","text":"开发阶段用的是 UnityEditor.EditorUtility.OpenFilePanel() 函数，简单易用。但是如其名所示，UnityEditor 只在 Unity 编辑器内可见，尝试 build 出 Windows 下 standalone 包时会报编译错误。 解决办法是用 mono 库下的相应功能实现打开文件。 在 Unity 安装根目录的 \\Editor\\Data\\Mono\\lib\\mono\\2.0\\ 路径下找到并复制 System.Windows.Forms.dll 粘贴 dll 文件到 Unity 项目的 Assets\\Plugins\\ 目录 PlayerSettings 中 Api Compatibility Level 选项值从默认的 .NET Standard 2.0 调整为 .NET 4.x 此时，dll 在 Unity 项目中变为可见，可以在脚本文件中使用 dll 中任意功能了。 选择文件对话框通过 System.Windows.Forms.OpenFileDialog 类实现，一个典型用法如下： 12345678System.Windows.Forms.OpenFileDialog ofd = new System.Windows.Forms.OpenFileDialog();ofd.Filter = &quot;Video Files(*.mp4;*.flv)|*.mp4;*.flv&quot;;ofd.RestoreDirectory = true;if (ofd.ShowDialog() != System.Windows.Forms.DialogResult.OK){ return; // user clicked cancel.}var filePath = ofd.FileName; //filePath holds the file's full path. 具体用例参考我的 XOPlayer项目 issues: mono 实现的 OpenFileDialog 太丑了……是非基于宿主系统原生实现的。我用的 Unity 2018.4.14f1 提供的是 mono 2.0 版本，不知是否跟 mono 版本过旧有关。","link":"/2020/01/15/Unity%E4%B8%AD%E7%94%A8OpenFileDialog%E5%AE%9E%E7%8E%B0%E9%80%89%E6%8B%A9%E6%96%87%E4%BB%B6%E5%8A%9F%E8%83%BD/"},{"title":"使用 Unity 开发 Android VR 应用系列之三——实现场景管理器","text":"0. 需求分析绝大多数应用里，都会有类似的业务逻辑：从 A 页面跳转到 B 页面，执行一系列操作后返回 A 页面。 这看似寻常的操作流程，Unity 是不能天然支持的。Unity 的 SceneManager 和 Android 的 activity stacks 在”页面”管理策略上大概有以下不同： 加载 B 场景，默认会销毁 A 场景 这种情况下想实现返回功能，必须重新加载 A，并且还原 A 销毁前的所有状态（滚动条位置等等）——业务逻辑越复杂，要记住的状态越多，这个方案不具有普适性。可显式指定以 Additive 模式加载新场景，加载 B 后仍将 A 保留。但是： Additive 模式加载 B 后，A 不会被隐藏 绝大多数情况下，这也不是我们期望的行为。所以需要基于 Additive 逻辑更进一步，使 B 加载后 A 自动隐藏。 综上，SceneManager 并不满足常见需求，需要自己实现一个 “scene stack”，使多个场景形成 LIFO 的栈式结构。 1. 系统设计以一组类图表示各参与者及其关系： SceneStack 以链表保存场景上下文信息，负责场景的加载与销毁。 注意 SetFirstScene(string sceneName, ControllerBase controller) 函数。应用中第一个场景是由系统负责加载的，用户没有干预的余地，所以只能在其加载后通过此函数手工添加到栈里。 ControllerBase Controller 即是最上层 UI 元素（通常是一个 Canvas）关联的脚本（MonoBehaviour）组件。将 controller 同对应的场景同时保存到 SceneStack 中，即可通过 controller 函数控制场景的显示与隐藏。 如此，基本实现了”新场景加载时使旧场景隐藏而不销毁”的流程化、自动化。 2. 代码实现完整的代码实现在这里，同时提供一个两个场景的简单测试用例。 3. 总结其实，我一直在混用”场景”与 “UI” 的概念。以 MVC 模型解构 Unity 的 UI 系统，场景是 Controller，UI 是 View。所以准确地说，我上述所提到的显示/隐藏，目标不是场景，而是场景内的 UI 元素。 实际也确实如此，Scene 类是没有类似显示/隐藏的接口可用的，代码里操作的是场景内 UI 根元素。我之所以如此表述，只是单纯地想简化描述罢了——毕竟隐藏了所有 UI，就好像是场景隐藏了一样。","link":"/2020/05/01/Unity%E5%BC%80%E5%8F%91Android-VR%E5%BA%94%E7%94%A8%E4%B8%89%E2%80%94%E2%80%94%E5%AE%9E%E7%8E%B0%E5%9C%BA%E6%99%AF%E7%AE%A1%E7%90%86%E5%99%A8/"},{"title":"使用 Unity 开发 Android VR 应用系列之一——开发环境设置","text":"0. 读者定位 熟悉 Android 开发 对 C#/.NET 有一定了解 想学习如何通过 Unity 开发 Android 应用 Unity 是微软旗下的跨平台游戏/应用开发工具，C# 自然成为其首推支持的前端开发语言。C# 虽是从 Java 脱胎而出，经过近二十年的独立发展，已经成长为一门明显优于 Java 的现代化语言（这当然是我个人的主观见解）。我也发愿以此项目为起点，重新掌握 C#/.NET 的技术体系。 1. 开发环境一览 Windwos 10, 16 GB RAM, 1060 3GB+ 独显 Unity 对硬件具有一定要求，不仅指构建版本，开发过程中还需要频繁使用开发机运行调试项目，硬件配置对开发效率的影响还是比较大的。 Android Studio 环境（包括 SDK 和 NDK） 不确定 Unity 兼容所有 Android Studio 版本环境——毕竟 Android Studio 本身就存在比较显著的版本兼容性问题。所以如果你碰到项目配置相关的错误，建议尝试提高或降低 Android Studio/SDK/NDK 版本来解决。我个人的 Android Studio 环境是 Android Studio 3.5.3/SDK Platform 26/NDK r16b。 Unity 2018.4.14f1 Unity 存在多个并行版本，包括 2017/2018/2019 等系列。大版本间互不兼容，所以立项之初 Unity 版本选择是一个重要任务。版本选择大概有几个原则： 依赖方的要求，很多第三方 SDK 不保证兼容所有 Unity 版本 优先使用 LTS (Long Term Support) 版本，LTS 意味着官方的持续维护，版本质量更高 如果想体验所有新功能，优选 2019 版本；如果更注重产品的稳定性，优选 2018 版本。LTS 并不意味着会同步所有最新版本的大功能，所以 2018 LTS 的功能是弱于 2019 系列的 Visual Studio Community 2019 此项可选。通过一些渠道安装 Unity，会同时包含 Visual Studio Community 2017 的安装选项，这已经足够了。 Pico G2 4K 眼镜 我们应用的适配机型之一，我个人的最爱 2. 首次运行设置1) Unity 关联 Android 环境 启动 Unity，依次选中菜单项 Edit - Preferences - External Tools，显示如下: 按实际安装路径分别填充标注的两个选项。没有用到 NDK 时，此项可空。 2) Android App 构建配置 在 Unity 中依次选中菜单项 Edit - Project Settings，在弹出窗口中的左栏选中 Player 选项后，在右栏切换到 Android settings 标签页。 选项繁多，不一一介绍。强烈建议对照文档熟练掌握所有选项含义，这是十分有意义的。这里仅介绍几个”高级”选项。 2.1) 自定义 Gradle 脚本 选中 Publishing Settings 下拉菜单，勾选如上图标识选项。Unity 默认使用对用户隐藏的 gradle 脚本构建 App，使用自定义 gradle 脚本，给开发者提供了从更细粒度上干预构建过程的能力。 2.2) C# 脚本配置 在 Other Settings 下拉菜单中，按上图所示设置各选项。将 .NET 运行时版本提升到 4.x 的原因是可以使用 C# 6.0 特性。 3) Unity 关联 Visual Studio Preferences 窗口中的 External Tools 标签页中，有如下选项 如果你的 Visual Studio 是通过 Unity 安装器打包安装，这里已经自动关联；如果想手动切换到其它 Visual Studio 实例，可以通过点击这里，浏览本地安装目录，找到并选中 devenv.exe 即可。如果这里没有配置正确，在 Visual Studio 中打开脚本文件后将不能成功自动感知，且不能通过 “附加到 Unity” 功能实时调试脚本。虽然不影响脚本的正常编译，对开发效率无疑是巨大打击。 3. 后记文中所记并非一个完整的 “Unity 下开发 Android App 配置流程”，此种教程文档网络上已数不胜数，我也是参照此类文章迈出的第一步。此文的价值，恰恰在于它是对此类千篇一律的入门流水账的一个重要补充，是我开发过程中一些痛苦教训的精炼提取，可以让你的第一步迈得更扎实。叙事的同时，也掺杂了很多我个人的理解。限于认知，如有冒犯或错误或词不达意等负面情绪传递，凡此种种，请留言指正，谢谢。","link":"/2020/04/17/Unity%E5%BC%80%E5%8F%91Android-VR%E5%BA%94%E7%94%A8%E4%B8%80%E2%80%94%E2%80%94%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E8%AE%BE%E7%BD%AE/"},{"title":"使用 Unity 开发 Android VR 应用系列之二——使用 Animator 实现鼠标悬浮 UI 缩放动画效果","text":"0. 概览展示效果如下 完整的代码和示例在这里 实现上图所示的动画效果，涉及两个 Unity 知识点： Animator 组件 动态调整 UI 渲染顺序 1. 使用 Animator 实现缩放动画Animator 是一套灵活度跟复杂度同样高的动画系统。简单来讲，其运作原理是：定义若干 Animation Clip，将其在 Animator Controller 中通过 Transition 拼装成一个状态机；创建若干 Parameters，用户通过为其赋不同值控制状态转移。 套用到本例来说，就是： 创建两个 Animation Clip，一个用于放大，一个用于缩小 创建一个 Animator Controller，在其中创建两个状态，分别对应上边两个 Animation Clip 创建一个 bool 参数 hovering，射线进入时为 true，射线移开时为 false 创建两个 Transition，分别使 hovering = true 时执行放大动画，hovering = false 时执行缩小动画 最终，Animator Controller 中呈现如下的状态图： 2. 使用 Canvas 组件实现动态调整渲染顺序默认的 UI 渲染顺序是按其在场景中出现的先后顺序定义的。带来的一个问题是：当对靠前的 UI 做放大动画时，有可能和后面的 UI 重叠，导致当前选中 UI 被遮挡。 可以通过为 UI 添加 Canvas 组件解决此问题。 注意图中的 Graphic Raycaster 组件，需要同 Canvas 成对出现，否则 UI 不能正常处理射线事件。 内嵌的 Canvas 具有上图所示的属性。勾选 Override Sorting 后，通过修改 Order in Layer 项值即可自定义当前 UI 的渲染顺序，值越大，渲染顺序越靠后。 脚本代码如下： 123456789101112// 添加 Canvas 和 GraphicRaycaster 组件if (topWhenHover) // 仅在需要时动态添加相应组件{ if (GetComponent&lt;Canvas&gt;() == null) { gameObject.AddComponent&lt;Canvas&gt;(); } if (GetComponent&lt;GraphicRaycaster&gt;() == null) { gameObject.AddComponent&lt;GraphicRaycaster&gt;(); }} 1234567891011// hover 状态变化时private void OnHoverChanged(bool hover){ if (topWhenHover) { var canvas = GetComponent&lt;Canvas&gt;(); canvas.overrideSorting = hover; canvas.sortingOrder = sortingOrder; } ...} 3. 把所有功能封装到一个自定义组件中可以实现一个高度封装的组件：用户只需要添加此组件，即可自动监听射线进出事件并执行动画。 1. 使组件能接收射线进出事件12345678910111213// 实现对应接口public class HoverScaler : MonoBehaviour, IPointerEnterHandler, IPointerExitHandler{ public void OnPointerEnter(PointerEventData eventData) { OnHoverChanged(true); } public void OnPointerExit(PointerEventData eventData) { OnHoverChanged(false); }} 2. 添加 Animator 组件到 UI123456void Start() { animator = gameObject.AddComponent&lt;Animator&gt;(); var controller = Resources.Load&lt;RuntimeAnimatorController&gt;(&quot;Animations/ScaleWhenHover&quot;); animator.runtimeAnimatorController = Instantiate(controller); } 完整的组件实现在这里 4. Issues 修改 Canvas 的 sortingOrder 属性，会使其父 UI 的 mask 功能失效（demo 有演示）","link":"/2020/04/21/Unity%E5%BC%80%E5%8F%91Android-VR%E5%BA%94%E7%94%A8%E4%BA%8C%E2%80%94%E2%80%94Animator%E5%AE%9E%E7%8E%B0%E9%BC%A0%E6%A0%87%E6%82%AC%E6%B5%AEUI%E7%BC%A9%E6%94%BE%E5%8A%A8%E7%94%BB%E6%95%88%E6%9E%9C/"},{"title":"使用 Unity 开发 Android VR 应用系列之四——用 ScriptableObject 实现预加载","text":"ScriptableObject 是一个数据容器类，可以用它来存储与类实例无关的数据。ScriptableObject 一个主要用途是利用它存储共享资源（比如 Prefab），减少无谓的复制，降低内存使用。 比如说，场景 A 和场景 B 都需要一个登录对话框。常规做法是创建一个 Prefab，分别在 A 和 B 中各自实例化；为了节省内存，可以在 ScriptableObject 中实例此 Prefab，在运行时将此 Prefab 实例添加到 A/B 场景中。 ScriptableObject 最典型的一个应用场景，便是用它来实现预加载了。 如上图，在 Player Settings 的 Optimization 分类下有一个 Preloaded Assets 数组选项。数组列出的 .asset 类型的资源会在程序启动时加载，并一直存活到程序退出。 .asset 资源对应的就是 ScriptableObject。实现 ScriptableObject 类时，需使用 CreateAssetMenu 属性为此 ScriptableObject 在 Assets 菜单中创建一个使用入口： 123456789101112131415// 模仿 lua，创建一个名字为 G 的类，意指此类为 Global used.[CreateAssetMenu(fileName = &quot;GlobalAsset&quot;, menuName = &quot;GlobalAsset&quot;)]public class G : ScriptableObject{// 实例被加载后会触发此回调private void OnEnable(){// 缓存材质资源...// 预先创建对象池...}} 上边的示例代码在 Assets-Create 菜单栏下创建了一个 GlobalAsset 菜单项，通过此菜单项便可方便地创建一个 GlobalAsset.asset 的资源文件。将此资源文件添加到预加载数组中后，程序启动时就会自动实例化一个 G 类实例，实例在被加载后会触发 OnEnable 消息，可以在此回调中实现具体的预加载逻辑。 简言之，ScriptableObject 是 Unity 提供的可完美取代 Singleton 的内建数据共享机制。","link":"/2020/06/13/Unity%E5%BC%80%E5%8F%91Android-VR%E5%BA%94%E7%94%A8%E5%9B%9B%E2%80%94%E2%80%94ScriptableObject%E5%AE%9E%E7%8E%B0%E9%A2%84%E5%8A%A0%E8%BD%BD/"},{"title":"西安行有感","text":"西安一行，让我对地方美食文化的传播有了一些自己的思考。 比如凉皮、肉夹馍，味道跟我在广州吃到的一些无异，因为本身就是大众口味，制作也简单，应该是被原样继承了下来的。 一个反例是羊杂汤。在我们老家，羊杂汤、羊肉汤在制作流程上是一样的，无非是内容差别，所以最后呈现的味道，也大体是一样的。但是在西安，羊杂汤跟羊肉汤（水盆羊肉），简直是天差地别的两个东西。所谓正宗羊杂汤的味道，怕是非少数人不可承受吧？ 但是我不知道这两个东西是不是源自一处，也不知道我们老家的羊汤是不是源自西安。也许只是我道听途说惯了，给自己错误的植入了“天下羊汤出西安”的记忆？所以这句话就当做是免责声明了吧。 总之，经历了这么多次国内旅行，我已经对正宗地道的地方菜有了免疫。在家门口吃到的，都是经过演绎变化，做成了适合你口味的罢了。好吃却在别的地方做不出来、发展不起来的菜我反而没见过。所以不必太计较于是不是正宗，更没必要对发源地心心念念。 话虽如此，对西安的失望却尤其难以抚慰，那是我念叨了小半辈子的地方……","link":"/2019/12/10/%E8%A5%BF%E5%AE%89%E8%A1%8C%E6%9C%89%E6%84%9F/"},{"title":"XOPlayer 阶段性总结——使用 Unity 的 VideoPlayer 组件开发全景播放器","text":"项目地址 现在还只是一个简陋的单 Scene 的应用，但已具备基本的视频播放和播放控制能力： 本地视频播放 进度显示、跳转 暂停、恢复、停止 音量调节 视频源类型切换 播放界面如下： 0. 开发、运行环境 VS2019 Community。安装时务必勾选 Visual Studio Tools for Unity。 Unity 2018.4.14f1。运行时修改菜单 Edit-Preferences 的 External Tools 选项页中的 External Script Editor 项值，关联到 VS2019，方能在 VS2019 中正确识别 Unity 工程和源码。 AMD Ryzen7 1700 + GTX 1070 + DDR4 16GB 1. UI 布局一览 模块化的组合功能均以 Prefab 实现（蓝色组件）。Prefab 既提供了一种可复用手段（2次出现的 Slider 以同一 Prefab 实例化），又契合了高内聚，低耦合的设计理念。我的理解是：相比于直接在 Scene 中布局复杂界面，Prefab 是更优选择，能用则用。 注意 VideoPlayer 所在位置，出现在根 Canvas 之外，原因参考 2. VideoPlayer。 2. VideoPlayer 相关以流媒体角度解读 VideoPlayer 的话，VideoPlayer 是一个 demuxers，decoders 和 renders 的组合。注意这里说的渲染，非指渲染到 UI，而是以某种标准格式渲染到内存或显存，从内存/显存渲染到 UI 是用户职责。所以，VideoPlayer 被设计为非 UI 组件，这也是上文提到 VideoPlayer 为什么出现在根 Canvas 之外的原因。 VideoPlayer 提供了多种 Render Mode，适配不同的渲染场景，XOPlayer 只用到了 Render Texture 一种。此纹理须在脚本中动态创建并关联到 VideoPlayer ： 12345678910// make sure: mPlayer.prepareCompleted += onPrepareCompleted.// width &amp; height are available until prepared.private void onPrepareCompleted(VideoPlayer videoPlayer){ mVideoTexture = new RenderTexture((int)mPlayer.width, (int)mPlayer.height, 0, RenderTextureFormat.ARGB32); mPlayer.targetTexture = mVideoTexture; // attaching texture to material // attaching material to some kind of UI controls, e.g., Image, global Skybox. mPlayer.Play();} XOPlayer 支持普通视频和全景视频的播放，两者在渲染到 UI 时大不相同： 普通视频渲染到 Image 组件 全景视频渲染到全局 Skybox 或 Sphere 此逻辑应补充在 RenderTexture 创建后、视频播放前： 123456789101112// attaching texture to material// attaching material to some kind of UI controls, e.g., Image, global Skybox.if (mMode == PlayMode.kNormal) // normal videos{ video2DMaterial.mainTexture = mVideoTexture; normalPlayer.GetComponent&lt;Image&gt;().material = video2DMaterial;}else // panoramic videos{ videoPanoramicMaterial.mainTexture = mVideoTexture; RenderSettings.skybox = videoPanoramicMaterial;} video2DMaterial 是一个预先定义的材质，Shader 采用 “Unlit/Texture” videoPanoramicMaterial 是一个预先定义的材质，Shader 采用 “Skybox/Panoramic” 全景视频的视角又分为 180° 和 360°，可以通过预先定义 2 个不同的材质，Image Type 分别设置为 180 Degrees 和 360 Degrees 实现；也可以只创建一个材质，脚本中动态切换 Image Type : 123456789if (mMode == PlayMode.kPanoramic180) // 180 degrees panoramic videos{ videoPanoramicMaterial.SetFloat(&quot;_ImageType&quot;, 1f); }else // 360 degrees panoramic videos{ videoPanoramicMaterial.SetFloat(&quot;_ImageType&quot;, 0f);} 3. 其它3.1 全景视频的视角旋转 PC 上通过鼠标拖拽驱动视角旋转。天空盒内，只需要将 Main Camera 按其自身 position 沿 X/Y 轴旋转即可： 123456789101112private float rotateSpeed = 2.0f;// commonly, we track Input status in Update loop.void Update(){ if (Input.GetMouseButton(0)) // if left mouse button pressed down { // rotate about x asix transform.RotateAround(transform.position, Vector3.down, rotateSpeed * Input.GetAxis(&quot;Mouse X&quot;)); // rotate about y asix transform.RotateAround(transform.position, transform.right, rotateSpeed * Input.GetAxis(&quot;Mouse Y&quot;)); }} 3.2 鼠标点击任意处显示/隐藏工具栏 因为绝大部分逻辑均在 VideoPlayer 组件的脚本 PlayerManager 内实现，所以第一反应是通过 PlayerManager 实现 IPointerDownHandler, IPointerUpHandler 接口即可。 结论是不可以。上文已经提及，VideoPlayer 不是 UI 组件，没有 Rect Transform，所以它其实是不可能接受鼠标事件的。 所以需要在根 Canvas 上添加脚本，并实现 IPointerDownHandler, IPointerUpHandler ： 1234567891011121314public class PointerHandler : MonoBehaviour, IPointerDownHandler, IPointerUpHandler{ // attaching to PlayerManager script. public PlayerManager playerManager; public void OnPointerDown(PointerEventData eventData) { } public void OnPointerUp(PointerEventData eventData) { playerManager.OnPointerUp(); // we do actions in PlayerManager. }} 3.3 普通视频播放相关 普通视频的调用链是这样的： VideoPlayer——RenderTexture——video2DMaterial——normalPlayer 其中 RenderTexture 是动态创建的，直接导致 normalPlayer.GetComponent&lt;Image&gt;().material 属性不能通过 Inspector 面板关联（指 video2DMaterial——normalPlayer），甚至在 Start() 中赋值也不行。Image 画面不会随播放更新。没有找到相关资料支持，但是我反推的结论是： 123mVideoTexture = new RenderTexture((int)mPlayer.width, (int)mPlayer.height, 0, RenderTextureFormat.ARGB32);video2DMaterial.mainTexture = mVideoTexture;normalPlayer.GetComponent&lt;Image&gt;().material = video2DMaterial; 这三句的调用顺序是不能变动的。即需要先完备材质信息，才能将材质赋值给 Image (或其它 UI 组件 ?)。 停止播放时存在类似问题： 123mPlayer.Stop();// 这句赋空是必须的，否则 Image 变为不可重入，再播放视频时画面不能更新。normalPlayer.GetComponent&lt;Image&gt;().material = null; 结合创建时的三句代码反推，结论是：再次播放时 VideoTexture 是重新创建的，但是 video2DMaterial 不是，所以 normalPlayer 跟踪不到这个间接变化。 得出一个不知道对错的结论：一个调用链上的对象，最好要么全部静态创建，要么全部动态创建。4. Issues 基本功能缺失：快进、快退、循环 180° 全景视频的旋转角度是 360° 进度条 Slider 不能拖动（OnValueChanged 死循环） 全景视频变糊（存疑）","link":"/2020/02/02/xoplayer%E9%98%B6%E6%AE%B5%E6%80%A7%E6%80%BB%E7%BB%93/"},{"title":"VS2019 编译 QtPropertyBrowser 源码","text":"尝试在 VS 2019 中导入 QtPropertyBrowser 源码到 VS 工程（vcxproj）进行编译时，遇到如下编译错误： 12345671&gt;moc_qtpropertybrowser.cpp1&gt;E:\\QtPropertyBrowserDemo\\QtPropertyBrowserDemo\\x64\\Debug\\moc\\moc_qtbuttonpropertybrowser.cpp(94,29): error C2027: 使用了未定义类型“QtButtonPropertyBrowserPrivate”1&gt;E:\\QtPropertyBrowserDemo\\QtPropertyBrowserDemo\\qtpropertybrowser\\qtbuttonpropertybrowser.h(47): message : 参见“QtButtonPropertyBrowserPrivate”的声明1&gt;E:\\QtPropertyBrowserDemo\\QtPropertyBrowserDemo\\x64\\Debug\\moc\\moc_qtbuttonpropertybrowser.cpp(95,29): error C2027: 使用了未定义类型“QtButtonPropertyBrowserPrivate”1&gt;E:\\QtPropertyBrowserDemo\\QtPropertyBrowserDemo\\qtpropertybrowser\\qtbuttonpropertybrowser.h(47): message : 参见“QtButtonPropertyBrowserPrivate”的声明1&gt;E:\\QtPropertyBrowserDemo\\QtPropertyBrowserDemo\\x64\\Debug\\moc\\moc_qtbuttonpropertybrowser.cpp(96,29): error C2027: 使用了未定义类型“QtButtonPropertyBrowserPrivate”1&gt;E:\\QtPropertyBrowserDemo\\QtPropertyBrowserDemo\\qtpropertybrowser\\qtbuttonpropertybrowser.h(47): message : 参见“QtButtonPropertyBrowserPrivate”的声明 解决办法如下： 在 VS 项目目录内右键对应 moc 文件的头文件，选中属性—Qt Meta-Object Compiler—moc，将 C++ Dynamic Source 值从 “Output File” 改为 “Disable”，重新编译即可。 简言之，这个项的作用是将当前文件中 Qt 类生成的 moc 源文件在编译阶段动态添加到编译器的源码文件列表中。 因为 Private 类的定义在 x.cpp 文件而非 x.h 中，导致编译 moc_x.cpp 时找不到类定义。 项值 Disable 即不将 moc_x.cpp 动态添加到编译器中。这么做是没问题的，因为 QtPropertyBrowser 相关源文件的最后都已显式 include 了对应的 moc.cpp。 具体可参考： https://forum.qt.io/topic/119401/how-to-compile-source-code-of-qtpropertybrowser-by-vs2019-correctly https://www.qt.io/blog/2018/01/24/qt-visual-studio-new-approach-based-msbuild","link":"/2020/09/30/VS2019%E7%BC%96%E8%AF%91QtPropertyBrowser%E6%BA%90%E7%A0%81/"},{"title":"&#39;基于 FFmpeg 的视频编辑器开发—踩坑记&#39;","text":"折腾了两周，视频编辑器已初具规模： 解封装 解码 快速跳转和精准跳转 格式转换 缩放 重采样 添加文字 添加 srt 字幕 编码 封装 基本满足了当初想做一个 gif 生成器的需求，也是时候回顾下过去两周踩过的坑了。 1. av_seek_frame() 后解码，第一帧的 pts 仍为 seek 前的 ptsav_seek_frame() 是 avformat 模块接口，seek 后信息没有同步到 avcodec 模块。 seek 后马上调用 avcodec_flush_buffers() 即可。 2. 解码后视频帧 pts 为 AV_NOPTS_VALUEAV_NOPTS_VALUE 是一个极大的负数值的宏定义。pts 字段值是它时，说明此视频格式不支持或此视频未设置 pts。应把 pts 值设为同 pkt_dts 值： 1234// frame is a decoded AVFrameif (frame-&gt;pts == AV_NOPTS_VALUE) { frame-&gt;pts = frame-&gt;pkt_dts;} 3. av_read_frame() 后 调用 av_packet_unref() 释放 AVPacket 对象av_read_frame() 会将传入的 AVPacket 对象变为引用计数形态，或在传入 AVPacket 对象已经是引用计数形态时将计数 + 1，应用层负责在合适时机调用 av_packet_unref 将计数 - 1。否则 AVPacket 对象内缓存区将永远不会释放，导致内存泄漏。 4. 将滤镜图输出到文本文件进行调试分析这其实是个官方提供的命令行工具来的，叫 graph2dot 。只需将其中 print_digraph() 函数定义复制到自己的工程内，即可打印出如下图所示的滤镜图内的关系链： 结合 print_digraph() 源码和生成的文本描述，对 filter graph 的内部逻辑也能略窥一二。 5. 使音频滤镜吐出固定尺寸（采样数）许多音频编码器如 AAC，要求传递给 avcodec_send_frame() 的 AVFrame 对象包含固定尺寸（采样数）的音频数据，否则返回值将会是 AVERROR(EINVAL)。没必要自己缓存音频数据至指定尺寸再发送给编码器，可以直接调用 av_buffersink_set_frame_size() 接口，指示 sink 滤镜总是吐出指定尺寸的帧数据。 1234// 在 avfilter_graph_config() 后调用一次即可if (!(audioCodecContext-&gt;codec-&gt;capabilities &amp; AV_CODEC_CAP_VARIABLE_FRAME_SIZE)) { av_buffersink_set_frame_size(sinkContext, audioCodecContext-&gt;frame_size);} 未完待续…","link":"/2020/12/20/%E5%9F%BA%E4%BA%8EFFmpeg%E7%9A%84%E8%A7%86%E9%A2%91%E7%BC%96%E8%BE%91%E5%99%A8%E5%BC%80%E5%8F%91%E2%80%94%E8%B8%A9%E5%9D%91%E8%AE%B0/"}],"tags":[{"name":"C++","slug":"C","link":"/tags/C/"},{"name":"Unity","slug":"Unity","link":"/tags/Unity/"},{"name":"Animator","slug":"Animator","link":"/tags/Animator/"},{"name":"mono","slug":"mono","link":"/tags/mono/"},{"name":"VR","slug":"VR","link":"/tags/VR/"},{"name":"VideoPlayer","slug":"VideoPlayer","link":"/tags/VideoPlayer/"},{"name":"XOPlayer","slug":"XOPlayer","link":"/tags/XOPlayer/"},{"name":"西安","slug":"西安","link":"/tags/%E8%A5%BF%E5%AE%89/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"爬虫","slug":"爬虫","link":"/tags/%E7%88%AC%E8%99%AB/"},{"name":"Qt","slug":"Qt","link":"/tags/Qt/"}],"categories":[{"name":"杂记","slug":"杂记","link":"/categories/%E6%9D%82%E8%AE%B0/"},{"name":"StreamingCore","slug":"StreamingCore","link":"/categories/StreamingCore/"},{"name":"Unity","slug":"Unity","link":"/categories/Unity/"},{"name":"FFmpeg","slug":"FFmpeg","link":"/categories/FFmpeg/"},{"name":"使用 Unity 开发 Android VR 应用","slug":"使用-Unity-开发-Android-VR-应用","link":"/categories/%E4%BD%BF%E7%94%A8-Unity-%E5%BC%80%E5%8F%91-Android-VR-%E5%BA%94%E7%94%A8/"},{"name":"Qt","slug":"Qt","link":"/categories/Qt/"}]}